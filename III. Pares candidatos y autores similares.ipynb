{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Pares candidatos y Autores similares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte idetificaremos pares candidatos de tweets y aplicaremos thresholding para definir autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import itertools\n",
    "import ast\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Trabajo previo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = pd.read_csv('preprocesado.csv', converters={\"shingles\": ast.literal_eval})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidar FHs a partir de los archivos guardados en disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 203726)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FH = np.genfromtxt('fhs/file0.csv', delimiter=',')\n",
    "for i in range(1, 10):\n",
    "    FH2 = np.genfromtxt(f'fhs/file{i}.csv', delimiter=',')\n",
    "    FH = np.concatenate((FH, FH2), axis=1)\n",
    "FH.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar distancia m√≠nima a la que debe estar dos tweet para ser considerados pares candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 10\n",
    "b = 2\n",
    "round((1/b)**(1/r), 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar banding y obtener pares candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtuvimos 250425 pares candidatos, con b = 2 y r = 10\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/locality-sensitive-hashing-how-to-find-similar-items-in-a-large-set-with-precision-d907c52b05fc\n",
    "sig_mat = FH\n",
    "n, d = sig_mat.shape\n",
    "hashbuckets = collections.defaultdict(set)\n",
    "bands = np.array_split(sig_mat, b, axis=0)\n",
    "for i,band in enumerate(bands):\n",
    "    for j in range(d):\n",
    "        # The last value must be made a string, to prevent accidental\n",
    "        # key collisions of r+1 integers when we really only want\n",
    "        # keys of r integers plus a band index\n",
    "        band_id = tuple(list(band[:,j])+[str(i)])\n",
    "        hashbuckets[band_id].add(j)\n",
    "candidate_pairs = set()\n",
    "for bucket in hashbuckets.values():\n",
    "    if len(bucket) > 1:\n",
    "        for pair in itertools.combinations(bucket, 2):\n",
    "            candidate_pairs.add(pair)\n",
    "print(f\"Obtuvimos {len(candidate_pairs)} pares candidatos, con b = {b} y r = {r}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar pares de candidatos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitar tweets id√©nticos de los pares similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quedan 107584 pares candidatos\n"
     ]
    }
   ],
   "source": [
    "trimmed_cadidate_pairs = []\n",
    "for pair in candidate_pairs:\n",
    "        a, b = pair\n",
    "        text_a = resumen.text[a]\n",
    "        text_b = resumen.text[b]\n",
    "        if (text_a != text_b) and ('http' not in text_a) and ('http' not in text_b):\n",
    "                trimmed_cadidate_pairs.append((a, b))\n",
    "print(f\"Quedan {len(trimmed_cadidate_pairs)} pares candidatos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar 3 pares de tweets presuntamente similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. FarizoGonzales:  @Jaime_Bassa YA TERMINASTE TU TRABAJO O TE PAGAN PARA HACER CAMPA√ëA?\n",
      "ESùêé  SE LLAMA \n",
      "ùêëùêéùêÅùêé\n",
      "ùêÖùêëùêÑùêíùêÇùêîùêëùêÄ\n",
      "ùêéùêèùêéùêëùêìùêîùêçùêàùêíùêåùêé\n",
      "ùêëùêÑùêàùêëùêìùêÑ ùêÉùêÑùêã.ùêèùêîùêÑùêÅùêãùêé\n",
      "ùêÖùêÉùêë\n",
      "2. magiavioc:  @Jaime_Bassa HAGAN LO QUE HAGAN   DIGAN LO QUE  DIGAN   IGUAL SE IRAN DE  PATA EN EL CULO\n",
      "----------\n",
      "1. Araneddstr:  @Sinfiltros_tv @PanchoOrregoG @fernando_atria @fernando_atria va @PanchoOrregoG ponganle fecha.\n",
      "2. cristovich:  @jhonnygualtieri @Sinfiltros_tv @PanchoOrregoG @fernando_atria Las √°guilas no cazan moscas\n",
      "----------\n",
      "1. EsteOtro22:  @patriciapolitz @convencioncl @rkatrileo @MillaburAdolfo @ElisaLoncon @NoNeutrales IGNORANTE CTM üå≥\n",
      "2. maggiescobarC:  @nenerepublicana @patriciapolitz @convencioncl @rkatrileo @MillaburAdolfo @ElisaLoncon @NoNeutrales üëçüëçüëç\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for pair in random.sample(list(trimmed_cadidate_pairs), 3):\n",
    "    a, b = pair\n",
    "    print(f\"1. {resumen.screen_name[a]}: \",resumen.text[a])\n",
    "    print(f\"2. {resumen.screen_name[b]}: \",resumen.text[b])\n",
    "    print(\"----------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar autores similares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contar cuantos tweets similares hay para cada par de autores considerados candidatos similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = dict()\n",
    "\n",
    "def def_value():\n",
    "    return 0\n",
    "for pair in trimmed_cadidate_pairs:\n",
    "    a, b = pair\n",
    "    user_a = resumen.screen_name[a]\n",
    "    user_b = resumen.screen_name[b]\n",
    "    if user_a != user_b:\n",
    "        try:\n",
    "            count_dict[user_a][user_b] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_a] = collections.defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_a][user_b] += 1\n",
    "            \n",
    "        try:\n",
    "            count_dict[user_b][user_a] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_b] = collections.defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_b][user_a] += 1\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar solo los autores que est√°n por sobre un threshold de tweets similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1</th>\n",
       "      <th>user_2</th>\n",
       "      <th>sim_tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1607327</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802006</th>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801289</th>\n",
       "      <td>malahierba84</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798119</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>malahierba84</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797811</th>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831787</th>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791052</th>\n",
       "      <td>exevalpo</td>\n",
       "      <td>Cristia56264488</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795718</th>\n",
       "      <td>Cristia56264488</td>\n",
       "      <td>exevalpo</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621142</th>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797813</th>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621231</th>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831878</th>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611214</th>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>MCristi94737074</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607329</th>\n",
       "      <td>MCristi94737074</td>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468905</th>\n",
       "      <td>KiltroQuiltro</td>\n",
       "      <td>Caro75317658</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972807</th>\n",
       "      <td>Caro75317658</td>\n",
       "      <td>KiltroQuiltro</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836109</th>\n",
       "      <td>Gonzalo_qh</td>\n",
       "      <td>heliat33</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788026</th>\n",
       "      <td>Mejoremos_stgo</td>\n",
       "      <td>IKingEagle1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280265</th>\n",
       "      <td>IKingEagle1</td>\n",
       "      <td>Mejoremos_stgo</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437838</th>\n",
       "      <td>heliat33</td>\n",
       "      <td>Gonzalo_qh</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833521</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>bernardita_isa</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270082</th>\n",
       "      <td>bernardita_isa</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268458</th>\n",
       "      <td>Siulong21</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174013</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>Siulong21</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270080</th>\n",
       "      <td>Aviles2Angela</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272190</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>Aviles2Angela</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270079</th>\n",
       "      <td>Janet90476632</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409915</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>Janet90476632</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634207</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>caseoievski</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801301</th>\n",
       "      <td>RomilioValenzu4</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270853</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>RomilioValenzu4</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801287</th>\n",
       "      <td>caseoievski</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775860</th>\n",
       "      <td>Quenna4</td>\n",
       "      <td>silvanafati77</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270081</th>\n",
       "      <td>rodamaleh</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270078</th>\n",
       "      <td>mano_late</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269821</th>\n",
       "      <td>antonio18585272</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733651</th>\n",
       "      <td>silvanafati77</td>\n",
       "      <td>Quenna4</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423355</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>antonio18585272</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097926</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>mano_late</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395624</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>rodamaleh</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_1           user_2  sim_tweet_count\n",
       "1607327      osotroncoso     x1educalidad            131.0\n",
       "2802006     x1educalidad      osotroncoso            131.0\n",
       "2801289     malahierba84      osotroncoso            105.0\n",
       "2798119      osotroncoso     malahierba84            105.0\n",
       "1797811    MarVeraOjeda9   Pedro_Pablo_74             96.0\n",
       "831787    Pedro_Pablo_74    MarVeraOjeda9             96.0\n",
       "2791052         exevalpo  Cristia56264488             96.0\n",
       "2795718  Cristia56264488         exevalpo             96.0\n",
       "2621142   Pedro_Pablo_74    LusalguaJames             77.0\n",
       "1797813    LusalguaJames   Pedro_Pablo_74             77.0\n",
       "2621231    MarVeraOjeda9    LusalguaJames             48.0\n",
       "831878     LusalguaJames    MarVeraOjeda9             48.0\n",
       "1611214     x1educalidad  MCristi94737074             45.0\n",
       "1607329  MCristi94737074     x1educalidad             45.0\n",
       "468905     KiltroQuiltro     Caro75317658             34.0\n",
       "972807      Caro75317658    KiltroQuiltro             34.0\n",
       "1836109       Gonzalo_qh         heliat33             32.0\n",
       "4788026   Mejoremos_stgo      IKingEagle1             32.0\n",
       "3280265      IKingEagle1   Mejoremos_stgo             32.0\n",
       "2437838         heliat33       Gonzalo_qh             32.0\n",
       "3833521         Tol1Soto   bernardita_isa             30.0\n",
       "2270082   bernardita_isa         Tol1Soto             30.0\n",
       "2268458        Siulong21         Tol1Soto             30.0\n",
       "2174013         Tol1Soto        Siulong21             30.0\n",
       "2270080    Aviles2Angela         Tol1Soto             29.0\n",
       "2272190         Tol1Soto    Aviles2Angela             29.0\n",
       "2270079    Janet90476632         Tol1Soto             27.0\n",
       "4409915         Tol1Soto    Janet90476632             27.0\n",
       "3634207      osotroncoso      caseoievski             26.0\n",
       "2801301  RomilioValenzu4      osotroncoso             26.0\n",
       "270853       osotroncoso  RomilioValenzu4             26.0\n",
       "2801287      caseoievski      osotroncoso             26.0\n",
       "2775860          Quenna4    silvanafati77             25.0\n",
       "2270081        rodamaleh         Tol1Soto             25.0\n",
       "2270078        mano_late         Tol1Soto             25.0\n",
       "2269821  antonio18585272         Tol1Soto             25.0\n",
       "1733651    silvanafati77          Quenna4             25.0\n",
       "5423355         Tol1Soto  antonio18585272             25.0\n",
       "6097926         Tol1Soto        mano_late             25.0\n",
       "6395624         Tol1Soto        rodamaleh             25.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(count_dict).reset_index()\n",
    "count_long = pd.melt(count_df, id_vars='index')\n",
    "similar_authors = count_long[count_long.value >= 25].rename({'index': 'user_1', 'variable': 'user_2', 'value':'sim_tweet_count'}, axis = 1)\n",
    "similar_authors.sort_values(\"sim_tweet_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_authors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci√≥n para imprimir tweets de dos candidatos pares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tweets_from_candidates(user_1, user_2, amount):\n",
    "    iterations = 0\n",
    "    for pair in trimmed_cadidate_pairs:\n",
    "        a, b = pair\n",
    "        user_a = resumen.screen_name[a]\n",
    "        user_b = resumen.screen_name[b]\n",
    "        if ((user_a == user_1) and (user_b == user_2)) or ((user_b == user_1) and (user_a == user_2)):\n",
    "            print(\"By user \", user_a,\":\\n\",  f'\"{resumen.text[a]}\"\\n')\n",
    "            print(\"By user \", user_b, \":\\n\", f'\"{resumen.text[b]}\"')\n",
    "            print(\"_______________________________________________________\\n\")\n",
    "            if iterations == (amount-1):\n",
    "                break\n",
    "            iterations+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos tres ejemplos de pares de tweets de un par de autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By user  IKingEagle1 :\n",
      " \"@MHuaquimillaN @carmen_hertz #RechazoGanaEl4deSeptiembre #RechazoDeSalida2022 #RechazoDeSalida #Rechazo\"\n",
      "\n",
      "By user  Mejoremos_stgo :\n",
      " \"#RechazoDeSalida2022 #RechazoGanaEl4deSeptiembre #RechazoDeSalida #RechazoPopular\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  IKingEagle1 :\n",
      " \"@PierreCurieD #RechazoGanaEl4deSeptiembre #RechazoDeSalida2022 #RechazoDeSalida #Rechazo\"\n",
      "\n",
      "By user  Mejoremos_stgo :\n",
      " \"#RechazoDeSalida2022 #RechazoGanaEl4deSeptiembre #RechazoDeSalida #RechazoPopular\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  Mejoremos_stgo :\n",
      " \"Estos sdw valen hongo #RechazoDeSalida2022 #RechazoGanaEl4deSeptiembre #RechazoDeSalida #RechazoPopular\"\n",
      "\n",
      "By user  IKingEagle1 :\n",
      " \"@Cooperativa #RechazoGanaEl4deSeptiembre #RechazoDeSalida2022 #RechazoDeSalida #Rechazo\"\n",
      "_______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_tweets_from_candidates(\"Mejoremos_stgo\", \"IKingEagle1\", 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n podemos examinar un cierto n√∫mero de tweets para un n dado de autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre #AprueboPlebicitoDeSalida #AprueboNuevaConstitucion\n",
      "#AprueboDeSalida #Apruebo\"\n",
      "\n",
      "By user  RomilioValenzu4 :\n",
      " \"@MEQChile #AprueboPlebicitoDeSalida \n",
      "#AprueboDeSalida \n",
      "#Apruebo4deSeptiembre \n",
      "#AprueboNuevaConstitucion \n",
      "#LaConvencionSeDefiende\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre #AprueboPlebicitoDeSalida #AprueboNuevaConstitucion\n",
      "#AprueboDeSalida #Apruebo\"\n",
      "\n",
      "By user  RomilioValenzu4 :\n",
      " \"@MillaburAdolfo #AprueboPlebicitoDeSalida \n",
      "#AprueboDeSalida \n",
      "#Apruebo4deSeptiembre \n",
      "#AprueboNuevaConstitucion \n",
      "#LaConvencionSeDefiende\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  RomilioValenzu4 :\n",
      " \"@MillaburAdolfo #AprueboPlebicitoDeSalida \n",
      "#AprueboDeSalida \n",
      "#Apruebo4deSeptiembre \n",
      "#AprueboNuevaConstitucion \n",
      "#LaConvencionSeDefiende\"\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre #AprueboPlebicitoDeSalida #AprueboNuevaConstitucion\n",
      "#AprueboDeSalida #Apruebo\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  Caro75317658 :\n",
      " \"@KiltroQuiltro @lguerrero1964 @berfontaine @puapette @tudia_13 @gabrielboric Fundamente usted q dio esa informaci√≥n\"\n",
      "\n",
      "By user  KiltroQuiltro :\n",
      " \"@puapette @Caro75317658 @lguerrero1964 @berfontaine @tudia_13 @gabrielboric Las afp¬¥s no se acaban, informese\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  Caro75317658 :\n",
      " \"@KiltroQuiltro @lguerrero1964 @berfontaine @puapette @tudia_13 @gabrielboric El estado\"\n",
      "\n",
      "By user  KiltroQuiltro :\n",
      " \"@Caro75317658 @lguerrero1964 @berfontaine @puapette @tudia_13 @gabrielboric Google, busque.\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  Caro75317658 :\n",
      " \"@KiltroQuiltro @lguerrero1964 @berfontaine @puapette @tudia_13 @gabrielboric Donde est√°?\"\n",
      "\n",
      "By user  KiltroQuiltro :\n",
      " \"@Caro75317658 @lguerrero1964 @berfontaine @puapette @tudia_13 @gabrielboric üòÇ Claro, la pandemia en el 2019\"\n",
      "_______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def shown_n_similar_authors_examples(n_author_pairs, n_examples_per_pair):\n",
    "    iteration = 0\n",
    "    for index, row in similar_authors.iterrows():\n",
    "        user_1 = row.user_1\n",
    "        user_2 = row.user_2\n",
    "        show_tweets_from_candidates(user_1, user_2, n_examples_per_pair) # Sacar 3 ejemplos por cada par\n",
    "        if iteration == (n_author_pairs-1):\n",
    "            break\n",
    "        iteration += 1\n",
    "shown_n_similar_authors_examples(2, 3)\n",
    "# Se mostraran 3 ejemplos para 2 pares de autores similares: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareas_proce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
