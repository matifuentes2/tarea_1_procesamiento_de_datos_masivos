{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Pares candidatos y Autores similares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte idetificaremos pares candidatos de tweets y aplicaremos thresholding para definir autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import itertools\n",
    "import ast\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Trabajo previo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = pd.read_csv('preprocesado.csv', converters={\"shingles\": ast.literal_eval})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidar FHs a partir de los archivos guardados en disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 203726)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FH = np.genfromtxt('fhs/file0.csv', delimiter=',')\n",
    "for i in range(1, 10):\n",
    "    FH2 = np.genfromtxt(f'fhs/file{i}.csv', delimiter=',')\n",
    "    FH = np.concatenate((FH, FH2), axis=1)\n",
    "FH.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar distancia mínima a la que debe estar dos tweet para ser considerados pares candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 10\n",
    "b = 2\n",
    "round((1/b)**(1/r), 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar banding y obtener pares candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtuvimos 250425 pares candidatos, con b = 2 y r = 10\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/locality-sensitive-hashing-how-to-find-similar-items-in-a-large-set-with-precision-d907c52b05fc\n",
    "sig_mat = FH\n",
    "n, d = sig_mat.shape\n",
    "hashbuckets = collections.defaultdict(set)\n",
    "bands = np.array_split(sig_mat, b, axis=0)\n",
    "for i,band in enumerate(bands):\n",
    "    for j in range(d):\n",
    "        # The last value must be made a string, to prevent accidental\n",
    "        # key collisions of r+1 integers when we really only want\n",
    "        # keys of r integers plus a band index\n",
    "        band_id = tuple(list(band[:,j])+[str(i)])\n",
    "        hashbuckets[band_id].add(j)\n",
    "candidate_pairs = set()\n",
    "for bucket in hashbuckets.values():\n",
    "    if len(bucket) > 1:\n",
    "        for pair in itertools.combinations(bucket, 2):\n",
    "            candidate_pairs.add(pair)\n",
    "print(f\"Obtuvimos {len(candidate_pairs)} pares candidatos, con b = {b} y r = {r}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar pares de candidatos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitar tweets idénticos de los pares similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quedan 107584 pares candidatos\n"
     ]
    }
   ],
   "source": [
    "trimmed_cadidate_pairs = []\n",
    "for pair in candidate_pairs:\n",
    "        a, b = pair\n",
    "        text_a = resumen.text[a]\n",
    "        text_b = resumen.text[b]\n",
    "        if (text_a != text_b) and ('http' not in text_a) and ('http' not in text_b):\n",
    "                trimmed_cadidate_pairs.append((a, b))\n",
    "print(f\"Quedan {len(trimmed_cadidate_pairs)} pares candidatos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar 3 pares de tweets presuntamente similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. FarizoGonzales:  @Jaime_Bassa YA TERMINASTE TU TRABAJO O TE PAGAN PARA HACER CAMPAÑA?\n",
      "ES𝐎  SE LLAMA \n",
      "𝐑𝐎𝐁𝐎\n",
      "𝐅𝐑𝐄𝐒𝐂𝐔𝐑𝐀\n",
      "𝐎𝐏𝐎𝐑𝐓𝐔𝐍𝐈𝐒𝐌𝐎\n",
      "𝐑𝐄𝐈𝐑𝐓𝐄 𝐃𝐄𝐋.𝐏𝐔𝐄𝐁𝐋𝐎\n",
      "𝐅𝐃𝐑\n",
      "2. magiavioc:  @Jaime_Bassa HAGAN LO QUE HAGAN   DIGAN LO QUE  DIGAN   IGUAL SE IRAN DE  PATA EN EL CULO\n",
      "----------\n",
      "1. Araneddstr:  @Sinfiltros_tv @PanchoOrregoG @fernando_atria @fernando_atria va @PanchoOrregoG ponganle fecha.\n",
      "2. cristovich:  @jhonnygualtieri @Sinfiltros_tv @PanchoOrregoG @fernando_atria Las águilas no cazan moscas\n",
      "----------\n",
      "1. EsteOtro22:  @patriciapolitz @convencioncl @rkatrileo @MillaburAdolfo @ElisaLoncon @NoNeutrales IGNORANTE CTM 🌳\n",
      "2. maggiescobarC:  @nenerepublicana @patriciapolitz @convencioncl @rkatrileo @MillaburAdolfo @ElisaLoncon @NoNeutrales 👍👍👍\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for pair in random.sample(list(trimmed_cadidate_pairs), 3):\n",
    "    a, b = pair\n",
    "    print(f\"1. {resumen.screen_name[a]}: \",resumen.text[a])\n",
    "    print(f\"2. {resumen.screen_name[b]}: \",resumen.text[b])\n",
    "    print(\"----------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar autores similares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contar cuantos tweets similares hay para cada par de autores considerados candidatos similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = dict()\n",
    "\n",
    "def def_value():\n",
    "    return 0\n",
    "for pair in trimmed_cadidate_pairs:\n",
    "    a, b = pair\n",
    "    user_a = resumen.screen_name[a]\n",
    "    user_b = resumen.screen_name[b]\n",
    "    if user_a != user_b:\n",
    "        try:\n",
    "            count_dict[user_a][user_b] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_a] = collections.defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_a][user_b] += 1\n",
    "            \n",
    "        try:\n",
    "            count_dict[user_b][user_a] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_b] = collections.defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_b][user_a] += 1\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar solo los autores que están por sobre un threshold de tweets similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1</th>\n",
       "      <th>user_2</th>\n",
       "      <th>sim_tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1607327</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802006</th>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801289</th>\n",
       "      <td>malahierba84</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798119</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>malahierba84</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797811</th>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831787</th>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791052</th>\n",
       "      <td>exevalpo</td>\n",
       "      <td>Cristia56264488</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795718</th>\n",
       "      <td>Cristia56264488</td>\n",
       "      <td>exevalpo</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621142</th>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797813</th>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>Pedro_Pablo_74</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621231</th>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831878</th>\n",
       "      <td>LusalguaJames</td>\n",
       "      <td>MarVeraOjeda9</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611214</th>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>MCristi94737074</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607329</th>\n",
       "      <td>MCristi94737074</td>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468905</th>\n",
       "      <td>KiltroQuiltro</td>\n",
       "      <td>Caro75317658</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972807</th>\n",
       "      <td>Caro75317658</td>\n",
       "      <td>KiltroQuiltro</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836109</th>\n",
       "      <td>Gonzalo_qh</td>\n",
       "      <td>heliat33</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788026</th>\n",
       "      <td>Mejoremos_stgo</td>\n",
       "      <td>IKingEagle1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280265</th>\n",
       "      <td>IKingEagle1</td>\n",
       "      <td>Mejoremos_stgo</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437838</th>\n",
       "      <td>heliat33</td>\n",
       "      <td>Gonzalo_qh</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833521</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>bernardita_isa</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270082</th>\n",
       "      <td>bernardita_isa</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268458</th>\n",
       "      <td>Siulong21</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174013</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>Siulong21</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270080</th>\n",
       "      <td>Aviles2Angela</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272190</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>Aviles2Angela</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270079</th>\n",
       "      <td>Janet90476632</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409915</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>Janet90476632</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634207</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>caseoievski</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801301</th>\n",
       "      <td>RomilioValenzu4</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270853</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>RomilioValenzu4</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801287</th>\n",
       "      <td>caseoievski</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775860</th>\n",
       "      <td>Quenna4</td>\n",
       "      <td>silvanafati77</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270081</th>\n",
       "      <td>rodamaleh</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270078</th>\n",
       "      <td>mano_late</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269821</th>\n",
       "      <td>antonio18585272</td>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733651</th>\n",
       "      <td>silvanafati77</td>\n",
       "      <td>Quenna4</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423355</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>antonio18585272</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097926</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>mano_late</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395624</th>\n",
       "      <td>Tol1Soto</td>\n",
       "      <td>rodamaleh</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_1           user_2  sim_tweet_count\n",
       "1607327      osotroncoso     x1educalidad            131.0\n",
       "2802006     x1educalidad      osotroncoso            131.0\n",
       "2801289     malahierba84      osotroncoso            105.0\n",
       "2798119      osotroncoso     malahierba84            105.0\n",
       "1797811    MarVeraOjeda9   Pedro_Pablo_74             96.0\n",
       "831787    Pedro_Pablo_74    MarVeraOjeda9             96.0\n",
       "2791052         exevalpo  Cristia56264488             96.0\n",
       "2795718  Cristia56264488         exevalpo             96.0\n",
       "2621142   Pedro_Pablo_74    LusalguaJames             77.0\n",
       "1797813    LusalguaJames   Pedro_Pablo_74             77.0\n",
       "2621231    MarVeraOjeda9    LusalguaJames             48.0\n",
       "831878     LusalguaJames    MarVeraOjeda9             48.0\n",
       "1611214     x1educalidad  MCristi94737074             45.0\n",
       "1607329  MCristi94737074     x1educalidad             45.0\n",
       "468905     KiltroQuiltro     Caro75317658             34.0\n",
       "972807      Caro75317658    KiltroQuiltro             34.0\n",
       "1836109       Gonzalo_qh         heliat33             32.0\n",
       "4788026   Mejoremos_stgo      IKingEagle1             32.0\n",
       "3280265      IKingEagle1   Mejoremos_stgo             32.0\n",
       "2437838         heliat33       Gonzalo_qh             32.0\n",
       "3833521         Tol1Soto   bernardita_isa             30.0\n",
       "2270082   bernardita_isa         Tol1Soto             30.0\n",
       "2268458        Siulong21         Tol1Soto             30.0\n",
       "2174013         Tol1Soto        Siulong21             30.0\n",
       "2270080    Aviles2Angela         Tol1Soto             29.0\n",
       "2272190         Tol1Soto    Aviles2Angela             29.0\n",
       "2270079    Janet90476632         Tol1Soto             27.0\n",
       "4409915         Tol1Soto    Janet90476632             27.0\n",
       "3634207      osotroncoso      caseoievski             26.0\n",
       "2801301  RomilioValenzu4      osotroncoso             26.0\n",
       "270853       osotroncoso  RomilioValenzu4             26.0\n",
       "2801287      caseoievski      osotroncoso             26.0\n",
       "2775860          Quenna4    silvanafati77             25.0\n",
       "2270081        rodamaleh         Tol1Soto             25.0\n",
       "2270078        mano_late         Tol1Soto             25.0\n",
       "2269821  antonio18585272         Tol1Soto             25.0\n",
       "1733651    silvanafati77          Quenna4             25.0\n",
       "5423355         Tol1Soto  antonio18585272             25.0\n",
       "6097926         Tol1Soto        mano_late             25.0\n",
       "6395624         Tol1Soto        rodamaleh             25.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(count_dict).reset_index()\n",
    "count_long = pd.melt(count_df, id_vars='index')\n",
    "similar_authors = count_long[count_long.value >= 25].rename({'index': 'user_1', 'variable': 'user_2', 'value':'sim_tweet_count'}, axis = 1)\n",
    "similar_authors.sort_values(\"sim_tweet_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_authors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para imprimir tweets de dos candidatos pares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tweets_from_candidates(user_1, user_2, amount):\n",
    "    iterations = 0\n",
    "    for pair in trimmed_cadidate_pairs:\n",
    "        a, b = pair\n",
    "        user_a = resumen.screen_name[a]\n",
    "        user_b = resumen.screen_name[b]\n",
    "        if ((user_a == user_1) and (user_b == user_2)) or ((user_b == user_1) and (user_a == user_2)):\n",
    "            print(\"By user \", user_a,\":\\n\",  f'\"{resumen.text[a]}\"\\n')\n",
    "            print(\"By user \", user_b, \":\\n\", f'\"{resumen.text[b]}\"')\n",
    "            print(\"_______________________________________________________\\n\")\n",
    "            if iterations == (amount-1):\n",
    "                break\n",
    "            iterations+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos tres ejemplos de pares de tweets de un par de autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tweets_from_candidates(\"Natacha55538315\", \"MAJOCAPA196556\", 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación podemos examinar un cierto número de tweets para un n dado de autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By user  aurora4310 :\n",
      " \"@CamiRT7 @AprendizCrypto @pillan197811 @fernando_atria @DajacJara @AXELKAISER @rocicantuarias @danielstingo @MEQChile Se pico\"\n",
      "\n",
      "By user  JaggerGuti :\n",
      " \"@Elinis_Benetash @fernando_atria @DajacJara @AXELKAISER @rocicantuarias @danielstingo @MEQChile @GAMBA_CL O empiezo yo? 😂\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  JaggerGuti :\n",
      " \"@Elinis_Benetash @sotan_n @fernando_atria @DajacJara @AXELKAISER @rocicantuarias @danielstingo @MEQChile Propiedad y digna... 😂 😂 😂\"\n",
      "\n",
      "By user  aurora4310 :\n",
      " \"@AprendizCrypto @pillan197811 @fernando_atria @DajacJara @AXELKAISER @rocicantuarias @danielstingo @MEQChile No tienen ningún poder\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  JaggerGuti :\n",
      " \"@Elinis_Benetash @sotan_n @fernando_atria @DajacJara @AXELKAISER @rocicantuarias @danielstingo @MEQChile Propiedad y digna... 😂 😂 😂\"\n",
      "\n",
      "By user  aurora4310 :\n",
      " \"@AprendizCrypto @pillan197811 @fernando_atria @DajacJara @AXELKAISER @rocicantuarias @danielstingo @MEQChile Ponga el artículo completo.\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  aurora4310 :\n",
      " \"@DajacJara @Elinis_Benetash @FreityT @fernando_atria @AXELKAISER @rocicantuarias @danielstingo @MEQChile No tienes ni idea\"\n",
      "\n",
      "By user  ChandlerFruna :\n",
      " \"@Patolukas1991 @rocicantuarias @danielstingo Y que entendiste tu? Viste el video completo ?\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  ChandlerFruna :\n",
      " \"@Lore1415A @rocicantuarias @danielstingo Ajjajajajajajajajajajajajaja ajajajjajajajajaja ajajajajajaja ajajajjajajaa\"\n",
      "\n",
      "By user  aurora4310 :\n",
      " \"@Elinis_Benetash @FreityT @DajacJara @fernando_atria @AXELKAISER @rocicantuarias @danielstingo @MEQChile Deja de poner post chantas de la tv\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  aurora4310 :\n",
      " \"@AprendizCrypto @pillan197811 @fernando_atria @DajacJara @AXELKAISER @rocicantuarias @danielstingo @MEQChile No tienen ningún poder\"\n",
      "\n",
      "By user  ChandlerFruna :\n",
      " \"@Maret0RISQ @Ma__koch @rocicantuarias @danielstingo Lo único que saben ver, para lo demás son un asco ajajaja\"\n",
      "_______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def shown_n_similar_authors_examples(n_author_pairs, n_examples_per_pair):\n",
    "    iteration = 0\n",
    "    for index, row in similar_authors.iterrows():\n",
    "        user_1 = row.user_1\n",
    "        user_2 = row.user_2\n",
    "        show_tweets_from_candidates(user_1, user_2, n_examples_per_pair) # Sacar 3 ejemplos por cada par\n",
    "        if iteration == (n_author_pairs-1):\n",
    "            break\n",
    "        iteration += 1\n",
    "shown_n_similar_authors_examples(2, 3)\n",
    "# Se mostraran 3 ejemplos para 2 pares de autores similares: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareas_proce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
