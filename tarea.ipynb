{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matif/.pyenv/versions/3.10.0/envs/tareas_proce/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pre_procesamiento import pre_process\n",
    "from hashing import hash_signature_pool  \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from ray.util.multiprocessing import Pool\n",
    "import time\n",
    "import psutil\n",
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Pre-procesamiento de tweets:\n",
    "Las siguientes transformaciones fueron aplicadas al texto que posteriormente se usó para computar las firmas de hash.\n",
    "* Quitamos los retweets\n",
    "* Removemos stopwords del español\n",
    "* Quitamos los emoji\n",
    "* Quitamos los tweets que contienen un enlace, ya que suelen ser poco interesantes al limitarse a compartir ese enlace sin mayor comentario\n",
    "* Eliminamos los tweets que, tras aplicar todo el procesamiento anterior, tengan menos de 40 caracteres, ya que ralentizan la ejecución sin ser un mayor aporte a los resultados.\n",
    "\n",
    "Cada chunk fue guardado en disco por separado con pickle y eliminado de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "chunksize = 2500000\n",
    "shingles_dictionary = dict() # Diccionario que contendrá los set de shingles\n",
    "for indice, chunk in enumerate(pd.read_csv(\"tweets_2022_abril_junio.csv\", usecols=['screen_name', 'text'], chunksize=chunksize)):\n",
    "        if indice == 0:\n",
    "                prev_max_index = -1\n",
    "        update_dict, prev_max_index = pre_process(chunk, indice, prev_max_index+1)\n",
    "        shingles_dictionary.update(update_dict)\n",
    "del chunk\n",
    "del update_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. MinHash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos las firmas de hash usando el algoritmo [SuperMinHash](https://arxiv.org/abs/1706.05698). Paralelizamos con 4 nucleos para acortar tiempo. La cantidad de nucleos empleados responde a la cantidad de nucleos disponibles en la máquina al momento de ejecutar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 16:33:32,477\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "#%%capture --no-stdout\n",
    "core_count = psutil.cpu_count() # Obtener nucleos disponibles\n",
    "if core_count >= 6:\n",
    "    partition_n = 4 # Si tienes más de 6, usas 4\n",
    "else:\n",
    "    partition_n = max(1, core_count//2) # Si tienes menos, usas la mitad \n",
    "lista_dict = list(shingles_dictionary.items())\n",
    "largo = len(shingles_dictionary) // partition_n\n",
    "dicts = [dict(lista_dict[:largo])]\n",
    "for i in range(1,partition_n):\n",
    "    if i != 3:\n",
    "        dicts.append(dict(lista_dict[largo*i:largo*(i+1)]))\n",
    "    else:\n",
    "        dicts.append(dict(lista_dict[largo*i:]))\n",
    "with Pool() as p:\n",
    "    p.map(hash_signature_pool, [(dicc, 20, indice) for indice, dicc in enumerate(dicts)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargas las firmas de hash y consolidar en un único objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 750862)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"fhs/file0.obj\", 'rb') as file:\n",
    "    FH = pickle.load(file)\n",
    "\n",
    "for i in range(1, partition_n):\n",
    "    with open(f\"fhs/file{i}.obj\", 'rb') as file:\n",
    "        FH2 = pickle.load(file)\n",
    "        FH = np.concatenate((FH, FH2), axis=1)\n",
    "    del FH2\n",
    "FH.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a cargar los tweets pre-procesados en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_tweets/resumen0.obj', 'rb') as file:\n",
    "    resumen = pickle.load(file)\n",
    "with open('processed_tweets/resumen1.obj', 'rb') as file:\n",
    "    resumen = pd.concat([resumen, pickle.load(file)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. LSH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos parámetros para aplicar la técnica de banding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 10\n",
    "b = 2\n",
    "t = round((1/b)**(1/r), 2)\n",
    "t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra elección de b y r fija el umbral en 0.93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtuvimos 193907 pares candidatos, con b = 2 y r = 10\n"
     ]
    }
   ],
   "source": [
    "# Tomado de https://towardsdatascience.com/locality-sensitive-hashing-how-to-find-similar-items-in-a-large-set-with-precision-d907c52b05fc\n",
    "n, d = FH.shape\n",
    "hashbuckets = defaultdict(set)\n",
    "bands = np.array_split(FH, b, axis=0)\n",
    "for i,band in enumerate(bands):\n",
    "    for j in range(d):\n",
    "        # The last value must be made a string, to prevent accidental\n",
    "        # key collisions of r+1 integers when we really only want\n",
    "        # keys of r integers plus a band index\n",
    "        band_id = tuple(list(band[:,j])+[str(i)])\n",
    "        hashbuckets[band_id].add(j)\n",
    "candidate_pairs = set()\n",
    "for bucket in hashbuckets.values():\n",
    "    if len(bucket) > 1:\n",
    "        for pair in itertools.combinations(bucket, 2):\n",
    "            candidate_pairs.add(pair)\n",
    "print(f\"Obtuvimos {len(candidate_pairs)} pares candidatos, con b = {b} y r = {r}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podamos los tweets idénticos entre sí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quedan 142280 pares candidatos\n"
     ]
    }
   ],
   "source": [
    "trimmed_cadidate_pairs = []\n",
    "for pair in candidate_pairs:\n",
    "        a, b = pair\n",
    "        text_a = resumen.text[a]\n",
    "        text_b = resumen.text[b]\n",
    "        if (text_a != text_b):\n",
    "                trimmed_cadidate_pairs.append((a, b))\n",
    "print(f\"Quedan {len(trimmed_cadidate_pairs)} pares candidatos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar 5 ejemplos de tweets semejantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. hernanm71450955:  @fernando_atria @christianpviera @letelier_raul @tatiurru @amaya_alvez @vichomrtnz @marian_barreaux @l_eslava Armonizar qué?\n",
      "2. nicagandozurdo:  @fernando_atria @christianpviera @letelier_raul @tatiurru @amaya_alvez @vichomrtnz @marian_barreaux @l_eslava Armonizate la neurona\n",
      "----------\n",
      "1. cotecid:  @patriciapolitz @convencioncl @rkatrileo @MillaburAdolfo @ElisaLoncon @NoNeutrales No me gusta!!!\n",
      "2. Antoniocl_35:  @patriciapolitz @convencioncl @rkatrileo @MillaburAdolfo @ElisaLoncon @NoNeutrales Ya y?\n",
      "----------\n",
      "1. Academica2021:  @OssandonLira @cgajardop @convencioncl @felipeharboe Cara de raja\n",
      "2. fabio_fergo:  @OssandonLira @cgajardop @convencioncl @felipeharboe Te dejaron de wn\n",
      "----------\n",
      "1. jackyri18641013:  @RafaelTorrebl18 @tere_marinovic @rocicantuarias @Ktymontealegre 👍👍👍\n",
      "2. roja_colorada:  @RafaelTorrebl18 @tere_marinovic @rocicantuarias @Ktymontealegre Minoría perdedora!\n",
      "😅😂😁😄😆🤣😂🤣😆😄\n",
      "----------\n",
      "1. JCCONTACTOSUR:  @delosquesobran @danielstingo @PabloPincel\n",
      "2. FlorcillaC:  @delosquesobran @danielstingo Y quien heredará algo ??\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for pair in random.sample(trimmed_cadidate_pairs, 5):\n",
    "    a, b = pair\n",
    "    print(f\"1. {resumen.screen_name[a]}: \",resumen.text[a])\n",
    "    print(f\"2. {resumen.screen_name[b]}: \",resumen.text[b])\n",
    "    print(\"----------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatear como df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_1</th>\n",
       "      <th>tweet_2</th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@fernando_atria @christianpviera @letelier_rau...</td>\n",
       "      <td>@fernando_atria @christianpviera @letelier_rau...</td>\n",
       "      <td>LacombC</td>\n",
       "      <td>MariaPo78178726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por eso #YoVotoRechazo #RechazoElMamarracho #R...</td>\n",
       "      <td>#RechazoGanaEl4deSeptiembre \\n#RechazoElMamarr...</td>\n",
       "      <td>nanocarrasco42</td>\n",
       "      <td>mariellaandrea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Parisi_oficial @CaneloCarola @fernando_atria ...</td>\n",
       "      <td>@Parisi_oficial @CaneloCarola @fernando_atria ...</td>\n",
       "      <td>rocuantluz</td>\n",
       "      <td>Dharmabitch1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@delosquesobran @danielstingo @PabloPincel</td>\n",
       "      <td>@delosquesobran @danielstingo Jajajajajajajaja...</td>\n",
       "      <td>JCCONTACTOSUR</td>\n",
       "      <td>JulioDo89187637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@fernando_atria @christianpviera @letelier_rau...</td>\n",
       "      <td>@fernando_atria @christianpviera @letelier_rau...</td>\n",
       "      <td>xuxumeitor</td>\n",
       "      <td>nakata1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142275</th>\n",
       "      <td>@gdominguez_ @MEQChile @ElisaLoncon @Jaime_Bas...</td>\n",
       "      <td>@gdominguez_ @MEQChile @ElisaLoncon @Jaime_Bas...</td>\n",
       "      <td>JaquesSidoseux</td>\n",
       "      <td>TurtleBlind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142276</th>\n",
       "      <td>#RechazoCrece #RechazoTransversal #RechazoSalv...</td>\n",
       "      <td>#RechazoCrece #RechazoTransversal #RechazoSalv...</td>\n",
       "      <td>javalco16</td>\n",
       "      <td>javalco16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142277</th>\n",
       "      <td>@mcubillossigall @gabrielboric @izkia Shi shi</td>\n",
       "      <td>@mcubillossigall @gabrielboric Jajajajajaja</td>\n",
       "      <td>fherrerasoto</td>\n",
       "      <td>rodriguezdumbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142278</th>\n",
       "      <td>@delosquesobran @danielstingo QUE MIEDO LES DA!!!</td>\n",
       "      <td>@delosquesobran @danielstingo JAJAJAJAJAJAJAJA...</td>\n",
       "      <td>Valeria08925319</td>\n",
       "      <td>PAVLOLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142279</th>\n",
       "      <td>@patriciapolitz @convencioncl @rkatrileo @Mill...</td>\n",
       "      <td>@patriciapolitz @convencioncl @rkatrileo @Mill...</td>\n",
       "      <td>Gabotita</td>\n",
       "      <td>ccavallo1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet_1  \\\n",
       "0       @fernando_atria @christianpviera @letelier_rau...   \n",
       "1       Por eso #YoVotoRechazo #RechazoElMamarracho #R...   \n",
       "2       @Parisi_oficial @CaneloCarola @fernando_atria ...   \n",
       "3              @delosquesobran @danielstingo @PabloPincel   \n",
       "4       @fernando_atria @christianpviera @letelier_rau...   \n",
       "...                                                   ...   \n",
       "142275  @gdominguez_ @MEQChile @ElisaLoncon @Jaime_Bas...   \n",
       "142276  #RechazoCrece #RechazoTransversal #RechazoSalv...   \n",
       "142277      @mcubillossigall @gabrielboric @izkia Shi shi   \n",
       "142278  @delosquesobran @danielstingo QUE MIEDO LES DA!!!   \n",
       "142279  @patriciapolitz @convencioncl @rkatrileo @Mill...   \n",
       "\n",
       "                                                  tweet_2         author_1  \\\n",
       "0       @fernando_atria @christianpviera @letelier_rau...          LacombC   \n",
       "1       #RechazoGanaEl4deSeptiembre \\n#RechazoElMamarr...   nanocarrasco42   \n",
       "2       @Parisi_oficial @CaneloCarola @fernando_atria ...       rocuantluz   \n",
       "3       @delosquesobran @danielstingo Jajajajajajajaja...    JCCONTACTOSUR   \n",
       "4       @fernando_atria @christianpviera @letelier_rau...       xuxumeitor   \n",
       "...                                                   ...              ...   \n",
       "142275  @gdominguez_ @MEQChile @ElisaLoncon @Jaime_Bas...   JaquesSidoseux   \n",
       "142276  #RechazoCrece #RechazoTransversal #RechazoSalv...        javalco16   \n",
       "142277        @mcubillossigall @gabrielboric Jajajajajaja     fherrerasoto   \n",
       "142278  @delosquesobran @danielstingo JAJAJAJAJAJAJAJA...  Valeria08925319   \n",
       "142279  @patriciapolitz @convencioncl @rkatrileo @Mill...         Gabotita   \n",
       "\n",
       "               author_2  \n",
       "0       MariaPo78178726  \n",
       "1        mariellaandrea  \n",
       "2          Dharmabitch1  \n",
       "3       JulioDo89187637  \n",
       "4            nakata1970  \n",
       "...                 ...  \n",
       "142275      TurtleBlind  \n",
       "142276        javalco16  \n",
       "142277   rodriguezdumbo  \n",
       "142278          PAVLOLP  \n",
       "142279        ccavallo1  \n",
       "\n",
       "[142280 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for pair in trimmed_cadidate_pairs:\n",
    "    a, b = pair\n",
    "    result.append([resumen.text[a], resumen.text[b], resumen.screen_name[a], resumen.screen_name[b]])\n",
    "\n",
    "similar_tweets_df = pd.DataFrame(result, columns=['tweet_1', 'tweet_2', 'author_1', 'author_2'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autores Similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = dict()\n",
    "\n",
    "def def_value():\n",
    "    return 0\n",
    "for pair in trimmed_cadidate_pairs:\n",
    "    a, b = pair\n",
    "    user_a = resumen.screen_name[a]\n",
    "    user_b = resumen.screen_name[b]\n",
    "    if user_a != user_b:\n",
    "        try:\n",
    "            count_dict[user_a][user_b] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_a] = defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_a][user_b] += 1\n",
    "            \n",
    "        try:\n",
    "            count_dict[user_b][user_a] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_b] = defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_b][user_a] += 1\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar solo los autores que están por sobre un threshold de tweets similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1</th>\n",
       "      <th>user_2</th>\n",
       "      <th>sim_tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>796938</th>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796944</th>\n",
       "      <td>malahierba84</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509834</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>malahierba84</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807914</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798994</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>zarate620</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39416762</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>JuanJoseNahuel</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509784</th>\n",
       "      <td>paolaespejo7</td>\n",
       "      <td>malahierba84</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842192</th>\n",
       "      <td>malahierba84</td>\n",
       "      <td>paolaespejo7</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369986</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>imaureirac</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796966</th>\n",
       "      <td>imaureirac</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_1          user_2  sim_tweet_count\n",
       "796938    x1educalidad     osotroncoso            338.0\n",
       "796944    malahierba84     osotroncoso            338.0\n",
       "4509834    osotroncoso    malahierba84            338.0\n",
       "807914     osotroncoso    x1educalidad            338.0\n",
       "14798994   osotroncoso       zarate620            182.0\n",
       "...                ...             ...              ...\n",
       "39416762   osotroncoso  JuanJoseNahuel             28.0\n",
       "4509784   paolaespejo7    malahierba84             27.0\n",
       "1842192   malahierba84    paolaespejo7             27.0\n",
       "5369986    osotroncoso      imaureirac             26.0\n",
       "796966      imaureirac     osotroncoso             26.0\n",
       "\n",
       "[450 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(count_dict).reset_index()\n",
    "count_long = pd.melt(count_df, id_vars='index')\n",
    "similar_authors = count_long[count_long.value >= 25].rename({'index': 'user_1', 'variable': 'user_2', 'value':'sim_tweet_count'}, axis = 1)\n",
    "similar_authors = similar_authors.sort_values(\"sim_tweet_count\", ascending=False)\n",
    "similar_authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para imprimir tweets de dos candidatos pares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tweets_from_candidates(user_1, user_2, amount):\n",
    "    iterations = 0\n",
    "    for pair in trimmed_cadidate_pairs:\n",
    "        a, b = pair\n",
    "        user_a = resumen.screen_name[a]\n",
    "        user_b = resumen.screen_name[b]\n",
    "        if ((user_a == user_1) and (user_b == user_2)) or ((user_b == user_1) and (user_a == user_2)):\n",
    "            print(\"By user \", user_a,\":\\n\",  f'\"{resumen.text[a]}\"\\n')\n",
    "            print(\"By user \", user_b, \":\\n\", f'\"{resumen.text[b]}\"')\n",
    "            print(\"_______________________________________________________\\n\")\n",
    "            if iterations == (amount-1):\n",
    "                break\n",
    "            iterations+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos dos ejemplos de pares de tweets escritos por autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion #Apruebo #AprueboDeSalida\"\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#AprueboDeSalida \n",
      "#Apruebo \n",
      "#Apruebo4deSeptiembre   \n",
      "#AprueboNuevaConstitución \n",
      "#AprueboPlebiscitoDeSalida\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre #AprueboPlebicitoDeSalida #AprueboNuevaConstitucion\n",
      "#AprueboDeSalida #Apruebo\"\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#AprueboPlebiscitoDeSalida \n",
      "#Apruebo4deSeptiembre \n",
      "#apruebo\n",
      "#AprueboNuevaConstitucion\"\n",
      "_______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_tweets_from_candidates(\"x1educalidad\", \"osotroncoso\", 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación podemos examinar un cierto número de tweets para un n dado de autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By user  xuxumeitor :\n",
      " \"@delosquesobran @danielstingo Cállate CTM!!!\"\n",
      "\n",
      "By user  JCCONTACTOSUR :\n",
      " \"@delosquesobran @danielstingo @PabloPincel\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  xuxumeitor :\n",
      " \"@delosquesobran @danielstingo Cállate CTM!!!\"\n",
      "\n",
      "By user  JCCONTACTOSUR :\n",
      " \"@delosquesobran @danielstingo @PabloPincel\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  xuxumeitor :\n",
      " \"@delosquesobran @danielstingo Cállate CTM!!!\"\n",
      "\n",
      "By user  JCCONTACTOSUR :\n",
      " \"@delosquesobran @danielstingo @PabloPincel\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  clavijerosexto :\n",
      " \"@delosquesobran @danielstingo Wn penca jajaja\"\n",
      "\n",
      "By user  JCCONTACTOSUR :\n",
      " \"@delosquesobran @danielstingo @PabloPincel\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  JCCONTACTOSUR :\n",
      " \"@delosquesobran @danielstingo @PabloPincel\"\n",
      "\n",
      "By user  clavijerosexto :\n",
      " \"@delosquesobran @danielstingo Wn penca jajaja\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  JCCONTACTOSUR :\n",
      " \"@delosquesobran @danielstingo @PabloPincel\"\n",
      "\n",
      "By user  clavijerosexto :\n",
      " \"@delosquesobran @danielstingo Wn penca jajaja\"\n",
      "_______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def shown_n_similar_authors_examples(n_examples_per_pair, n_author_pairs):\n",
    "    iteration = 0\n",
    "    for index, row in similar_authors.iterrows():\n",
    "        user_1 = row.user_1\n",
    "        user_2 = row.user_2\n",
    "        show_tweets_from_candidates(user_1, user_2, n_examples_per_pair) # Sacar 3 ejemplos por cada par\n",
    "        if iteration == (n_author_pairs-1):\n",
    "            break\n",
    "        iteration += 1\n",
    "shown_n_similar_authors_examples(3, 2)\n",
    "# Se mostraran 3 ejemplos para 2 pares de autores similares: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.625787381331126"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiempo_total = time.time() - start\n",
    "tiempo_total / 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
