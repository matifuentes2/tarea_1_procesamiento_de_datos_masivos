{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matif/.pyenv/versions/3.10.0/envs/tareas_proce/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pre_procesamiento import pre_process\n",
    "from hashing import hash_signature_pool  \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from ray.util.multiprocessing import Pool\n",
    "import time\n",
    "import psutil\n",
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Pre-procesamiento de tweets:\n",
    "Las siguientes transformaciones fueron aplicadas al texto que posteriormente se us칩 para computar las firmas de hash.\n",
    "* Quitamos los retweets\n",
    "* Removemos stopwords del espa침ol\n",
    "* Quitamos los emoji\n",
    "* Quitamos los tweets que contienen un enlace, ya que suelen ser poco interesantes al limitarse a compartir ese enlace sin mayor comentario\n",
    "* Eliminamos los tweets que, tras aplicar todo el procesamiento anterior, tengan menos de 20 caracteres, ya que nos pareci칩 que no representan un mayor aporte a los resultados.\n",
    "\n",
    "Cada chunk fue guardado en disco por separado con pickle y eliminado de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "chunksize = 2500000\n",
    "shingles_dictionary = dict() # Diccionario que contendr치 los set de shingles\n",
    "for indice, chunk in enumerate(pd.read_csv(\"tweets_2022_abril_junio.csv\", usecols=['screen_name', 'text'], chunksize=chunksize)):\n",
    "        if indice == 0:\n",
    "                prev_max_index = -1\n",
    "        update_dict, prev_max_index = pre_process(chunk, indice, prev_max_index+1)\n",
    "        shingles_dictionary.update(update_dict)\n",
    "del chunk\n",
    "del update_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. MinHash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos las firmas de hash usando el algoritmo [SuperMinHash](https://arxiv.org/abs/1706.05698). Paralelizamos con 4 nucleos para acortar tiempo. La cantidad de nucleos empleados responde a la cantidad de nucleos disponibles en la m치quina al momento de ejecutar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 12:14:26,448\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "#%%capture --no-stdout\n",
    "core_count = psutil.cpu_count() # Obtener nucleos disponibles\n",
    "if core_count >= 6:\n",
    "    partition_n = 4 # Si tienes m치s de 6, usas 4\n",
    "else:\n",
    "    partition_n = max(1, core_count//2) # Si tienes menos, usas la mitad \n",
    "lista_dict = list(shingles_dictionary.items())\n",
    "largo = len(shingles_dictionary) // partition_n\n",
    "dicts = [dict(lista_dict[:largo])]\n",
    "for i in range(1,partition_n):\n",
    "    if i != 3:\n",
    "        dicts.append(dict(lista_dict[largo*i:largo*(i+1)]))\n",
    "    else:\n",
    "        dicts.append(dict(lista_dict[largo*i:]))\n",
    "with Pool() as p:\n",
    "    p.map(hash_signature_pool, [(dicc, 20, indice) for indice, dicc in enumerate(dicts)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargas las firmas de hash y consolidar en un 칰nico objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 975932)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"fhs/file0.obj\", 'rb') as file:\n",
    "    FH = pickle.load(file)\n",
    "\n",
    "for i in range(1, partition_n):\n",
    "    with open(f\"fhs/file{i}.obj\", 'rb') as file:\n",
    "        FH2 = pickle.load(file)\n",
    "        FH = np.concatenate((FH, FH2), axis=1)\n",
    "    del FH2\n",
    "FH.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a cargar los tweets pre-procesados en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_tweets/resumen0.obj', 'rb') as file:\n",
    "    resumen = pickle.load(file)\n",
    "with open('processed_tweets/resumen1.obj', 'rb') as file:\n",
    "    resumen = pd.concat([resumen, pickle.load(file)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. LSH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos par치metros para aplicar la t칠cnica de banding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 10\n",
    "b = 2\n",
    "t = round((1/b)**(1/r), 2)\n",
    "t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra elecci칩n de b y r fija el umbral en 0.93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtuvimos 872437 pares candidatos, con b = 2 y r = 10\n"
     ]
    }
   ],
   "source": [
    "# Tomado de https://towardsdatascience.com/locality-sensitive-hashing-how-to-find-similar-items-in-a-large-set-with-precision-d907c52b05fc\n",
    "n, d = FH.shape\n",
    "hashbuckets = defaultdict(set)\n",
    "bands = np.array_split(FH, b, axis=0)\n",
    "for i,band in enumerate(bands):\n",
    "    for j in range(d):\n",
    "        # The last value must be made a string, to prevent accidental\n",
    "        # key collisions of r+1 integers when we really only want\n",
    "        # keys of r integers plus a band index\n",
    "        band_id = tuple(list(band[:,j])+[str(i)])\n",
    "        hashbuckets[band_id].add(j)\n",
    "candidate_pairs = set()\n",
    "for bucket in hashbuckets.values():\n",
    "    if len(bucket) > 1:\n",
    "        for pair in itertools.combinations(bucket, 2):\n",
    "            candidate_pairs.add(pair)\n",
    "print(f\"Obtuvimos {len(candidate_pairs)} pares candidatos, con b = {b} y r = {r}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podamos los tweets id칠nticos entre s칤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quedan 503119 pares candidatos\n"
     ]
    }
   ],
   "source": [
    "trimmed_cadidate_pairs = []\n",
    "for pair in candidate_pairs:\n",
    "        a, b = pair\n",
    "        text_a = resumen.text[a]\n",
    "        text_b = resumen.text[b]\n",
    "        if (text_a != text_b):\n",
    "                trimmed_cadidate_pairs.append((a, b))\n",
    "print(f\"Quedan {len(trimmed_cadidate_pairs)} pares candidatos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar 5 ejemplos de tweets semejantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Edwards32237132:  @Jaime_Bassa Rechazo.\n",
      "2. Wolfie____:  @Jaime_Bassa Rechazo!\n",
      "----------\n",
      "1. NormaJeanBake16:  @RobertoCeledonF @mentiraslared Ojal치 游똂\n",
      "2. albert_1917:  @RobertoCeledonF @mentiraslared Ya\n",
      "----------\n",
      "1. ElAnti_Fas:  @gdominguez_ @convencioncl Mentirosillo\n",
      "2. Alexiavivanco:  @gdominguez_ @convencioncl Mentiroso lun치tico\n",
      "----------\n",
      "1. aydeemoreno2013:  @fernando_atria FALSA.\n",
      "2. tomasprrr:  @fernando_atria Dicen\n",
      "----------\n",
      "1. CarmenMayo21:  @IgnacioAchurra RECHAZOOOOOOOOOOP.\n",
      "2. OSKARITO201245:  @IgnacioAchurra RECHAZOOOOOO\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for pair in random.sample(trimmed_cadidate_pairs, 5):\n",
    "    a, b = pair\n",
    "    print(f\"1. {resumen.screen_name[a]}: \",resumen.text[a])\n",
    "    print(f\"2. {resumen.screen_name[b]}: \",resumen.text[b])\n",
    "    print(\"----------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatear como df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_1</th>\n",
       "      <th>tweet_2</th>\n",
       "      <th>author_1</th>\n",
       "      <th>author_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@fernando_atria @christianpviera @letelier_rau...</td>\n",
       "      <td>@fernando_atria @christianpviera @letelier_rau...</td>\n",
       "      <td>torovoltan</td>\n",
       "      <td>Josea2tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Parisi_oficial @CaneloCarola @fernando_atria ...</td>\n",
       "      <td>@_alvaromunoz @Parisi_oficial @CaneloCarola @f...</td>\n",
       "      <td>Soyunalias</td>\n",
       "      <td>crstmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@patriciapolitz @convencioncl Exito !</td>\n",
       "      <td>@patriciapolitz @convencioncl #rechazo</td>\n",
       "      <td>Oso__03</td>\n",
       "      <td>Francis63499130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mcubillossigall @gabrielboric Rechazo</td>\n",
       "      <td>@mcubillossigall @gabrielboric Pin 1</td>\n",
       "      <td>BulboaMario</td>\n",
       "      <td>PabloPedemonte6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@tere_marinovic Jajajaja</td>\n",
       "      <td>@tere_marinovic Jajaja 游꾺</td>\n",
       "      <td>cadm12</td>\n",
       "      <td>CCasuario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_1  \\\n",
       "0  @fernando_atria @christianpviera @letelier_rau...   \n",
       "1  @Parisi_oficial @CaneloCarola @fernando_atria ...   \n",
       "2              @patriciapolitz @convencioncl Exito !   \n",
       "3             @mcubillossigall @gabrielboric Rechazo   \n",
       "4                           @tere_marinovic Jajajaja   \n",
       "\n",
       "                                             tweet_2     author_1  \\\n",
       "0  @fernando_atria @christianpviera @letelier_rau...   torovoltan   \n",
       "1  @_alvaromunoz @Parisi_oficial @CaneloCarola @f...   Soyunalias   \n",
       "2             @patriciapolitz @convencioncl #rechazo      Oso__03   \n",
       "3               @mcubillossigall @gabrielboric Pin 1  BulboaMario   \n",
       "4                           @tere_marinovic Jajaja 游꾺       cadm12   \n",
       "\n",
       "          author_2  \n",
       "0         Josea2tp  \n",
       "1         crstmart  \n",
       "2  Francis63499130  \n",
       "3  PabloPedemonte6  \n",
       "4        CCasuario  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for pair in trimmed_cadidate_pairs:\n",
    "    a, b = pair\n",
    "    result.append([resumen.text[a], resumen.text[b], resumen.screen_name[a], resumen.screen_name[b]])\n",
    "\n",
    "similar_tweets_df = pd.DataFrame(result, columns=['tweet_1', 'tweet_2', 'author_1', 'author_2'])\n",
    "similar_tweets_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autores Similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = dict()\n",
    "\n",
    "def def_value():\n",
    "    return 0\n",
    "for pair in trimmed_cadidate_pairs:\n",
    "    a, b = pair\n",
    "    user_a = resumen.screen_name[a]\n",
    "    user_b = resumen.screen_name[b]\n",
    "    if user_a != user_b:\n",
    "        try:\n",
    "            count_dict[user_a][user_b] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_a] = defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_a][user_b] += 1\n",
    "            \n",
    "        try:\n",
    "            count_dict[user_b][user_a] += 1\n",
    "        except KeyError:\n",
    "            count_dict[user_b] = defaultdict(def_value) # No retorna key error\n",
    "            count_dict[user_b][user_a] += 1\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar solo los autores que est치n por sobre un threshold de tweets similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_1</th>\n",
       "      <th>user_2</th>\n",
       "      <th>sim_tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26939121</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590548</th>\n",
       "      <td>x1educalidad</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590561</th>\n",
       "      <td>malahierba84</td>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53825421</th>\n",
       "      <td>osotroncoso</td>\n",
       "      <td>malahierba84</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42277822</th>\n",
       "      <td>Miltonterasss</td>\n",
       "      <td>alejandrazarzar</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83398957</th>\n",
       "      <td>tita_novoa</td>\n",
       "      <td>CeledonDani</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16784016</th>\n",
       "      <td>spastrian</td>\n",
       "      <td>Vickita58</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83398989</th>\n",
       "      <td>Libre1Chile</td>\n",
       "      <td>CeledonDani</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83399034</th>\n",
       "      <td>SitaLo</td>\n",
       "      <td>CeledonDani</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838020</th>\n",
       "      <td>verito_pes</td>\n",
       "      <td>DecapDomingo</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows 칑 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_1           user_2  sim_tweet_count\n",
       "26939121    osotroncoso     x1educalidad            323.0\n",
       "590548     x1educalidad      osotroncoso            323.0\n",
       "590561     malahierba84      osotroncoso            322.0\n",
       "53825421    osotroncoso     malahierba84            322.0\n",
       "42277822  Miltonterasss  alejandrazarzar            228.0\n",
       "...                 ...              ...              ...\n",
       "83398957     tita_novoa      CeledonDani             25.0\n",
       "16784016      spastrian        Vickita58             25.0\n",
       "83398989    Libre1Chile      CeledonDani             25.0\n",
       "83399034         SitaLo      CeledonDani             25.0\n",
       "7838020      verito_pes     DecapDomingo             25.0\n",
       "\n",
       "[900 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(count_dict).reset_index()\n",
    "count_long = pd.melt(count_df, id_vars='index')\n",
    "similar_authors = count_long[count_long.value >= 25].rename({'index': 'user_1', 'variable': 'user_2', 'value':'sim_tweet_count'}, axis = 1)\n",
    "similar_authors = similar_authors.sort_values(\"sim_tweet_count\", ascending=False)\n",
    "similar_authors.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funci칩n para imprimir tweets de dos candidatos pares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tweets_from_candidates(user_1, user_2, amount):\n",
    "    iterations = 0\n",
    "    for pair in trimmed_cadidate_pairs:\n",
    "        a, b = pair\n",
    "        user_a = resumen.screen_name[a]\n",
    "        user_b = resumen.screen_name[b]\n",
    "        if ((user_a == user_1) and (user_b == user_2)) or ((user_b == user_1) and (user_a == user_2)):\n",
    "            print(\"By user \", user_a,\":\\n\",  f'\"{resumen.text[a]}\"\\n')\n",
    "            print(\"By user \", user_b, \":\\n\", f'\"{resumen.text[b]}\"')\n",
    "            print(\"_______________________________________________________\\n\")\n",
    "            if iterations == (amount-1):\n",
    "                break\n",
    "            iterations+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos dos ejemplos de pares de tweets escritos por autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By user  x1educalidad :\n",
      " \"#AprueboDeSalida \n",
      "#Apruebo \n",
      "#Apruebo4deSeptiembre   \n",
      "#AprueboNuevaConstituci칩n \n",
      "#AprueboPlebiscitoDeSalida\"\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion #Apruebo #AprueboDeSalida\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion #Apruebo #AprueboDeSalida\"\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#AprueboDeSalida \n",
      "#Apruebo \n",
      "#Apruebo4deSeptiembre   \n",
      "#AprueboNuevaConstituci칩n \n",
      "#AprueboPlebiscitoDeSalida\"\n",
      "_______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_tweets_from_candidates(\"x1educalidad\", \"osotroncoso\", 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci칩n podemos examinar un cierto n칰mero de tweets para un n dado de autores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By user  x1educalidad :\n",
      " \"#AprueboDeSalida \n",
      "#Apruebo \n",
      "#Apruebo4deSeptiembre   \n",
      "#AprueboNuevaConstituci칩n \n",
      "#AprueboPlebiscitoDeSalida\"\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion #Apruebo #AprueboDeSalida\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion #Apruebo #AprueboDeSalida\"\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#AprueboDeSalida \n",
      "#Apruebo \n",
      "#Apruebo4deSeptiembre   \n",
      "#AprueboNuevaConstituci칩n \n",
      "#AprueboPlebiscitoDeSalida\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#Apruebo\n",
      "#AprueboPlebiscitoDeSalida\n",
      "#AprueboNuevaConstitucion\"\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo\n",
      "#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#AprueboDeSalida \n",
      "#Apruebo \n",
      "#Apruebo4deSeptiembre   \n",
      "#AprueboNuevaConstituci칩n \n",
      "#AprueboPlebiscitoDeSalida\"\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion #Apruebo #AprueboDeSalida\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion #Apruebo #AprueboDeSalida\"\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#AprueboDeSalida \n",
      "#Apruebo \n",
      "#Apruebo4deSeptiembre   \n",
      "#AprueboNuevaConstituci칩n \n",
      "#AprueboPlebiscitoDeSalida\"\n",
      "_______________________________________________________\n",
      "\n",
      "By user  x1educalidad :\n",
      " \"#Apruebo4deSeptiembre \n",
      "#Apruebo\n",
      "#AprueboPlebiscitoDeSalida\n",
      "#AprueboNuevaConstitucion\"\n",
      "\n",
      "By user  osotroncoso :\n",
      " \"#Apruebo\n",
      "#Apruebo4deSeptiembre \n",
      "#AprueboPlebiscitoDeSalida #AprueboNuevaConstitucion\"\n",
      "_______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def shown_n_similar_authors_examples(n_examples_per_pair, n_author_pairs):\n",
    "    iteration = 0\n",
    "    for index, row in similar_authors.iterrows():\n",
    "        user_1 = row.user_1\n",
    "        user_2 = row.user_2\n",
    "        show_tweets_from_candidates(user_1, user_2, n_examples_per_pair) # Sacar 3 ejemplos por cada par\n",
    "        if iteration == (n_author_pairs-1):\n",
    "            break\n",
    "        iteration += 1\n",
    "shown_n_similar_authors_examples(3, 2)\n",
    "# Se mostraran 3 ejemplos para 2 pares de autores similares: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.815567966302236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiempo_total = time.time() - start\n",
    "tiempo_total / 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
