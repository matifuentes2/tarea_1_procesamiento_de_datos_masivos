{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Pre-procesamiento de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como disponemos de recursos computacionales limitados, adoptaremos una serie de supuestos razonables que nos permitan acotar el espacio de comparación, a la vez que se obtenga un resultado razonablemente bueno."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import y funciones de limpieza de String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correr estas dos líneas solo la primera vez si no has instalado nltk\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from math import floor, comb\n",
    "\n",
    "#https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "def remove_emojis(text):\n",
    "    \"\"\"\n",
    "    Devuelve texto (idealmente) sin emojis\n",
    "    \"\"\"\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', text)\n",
    "stopwords = set(stopwords.words('spanish'))\n",
    "#https://stackoverflow.com/questions/25346058/removing-list-of-words-from-a-string\n",
    "def filter_sentence(text):\n",
    "    querywords = text.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in stopwords]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result\n",
    "\n",
    "# Quitar caracteres raros\n",
    "def remove_weird(text):\n",
    "    return ''.join([c for c in text if ord(c) < 128])\n",
    "\n",
    "# Aplicar todas las funciones anteriores\n",
    "def string_clean_pipeline(text):\n",
    "    text = remove_weird(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = filter_sentence(text)\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para crear funciones de hash tomada del material de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_hash(a, b, p, n):\n",
    "    def f(x):\n",
    "        return ((a * x + b) % p) % n\n",
    "    return f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos y muestran los usuarios únicos así como la cantidad de combinaciones de pares candidatos posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios únicos: 208139\n",
      "Posibles combinaciones: 21660817591\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets_2022_abril_junio.csv\")\n",
    "unicos = df.screen_name.unique()\n",
    "print(f\"Usuarios únicos: {len(unicos)}\") \n",
    "print(f\"Posibles combinaciones: {comb(len(unicos), 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservaremos solo las columnas de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ['id', 'screen_name', 'text']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero quitaremos los retweets porque obviamente son muy similares entre ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1512186668387913732</td>\n",
       "      <td>simonlodijo</td>\n",
       "      <td>@unveranonaranja @ruidosafest @franciscamusic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1512186985850544129</td>\n",
       "      <td>MacaSimplemente</td>\n",
       "      <td>@LaSuRivas @ElisaLoncon @siliconvalle @Valdebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1512187189974683661</td>\n",
       "      <td>LuisVer75699645</td>\n",
       "      <td>@teanval0207 @izkia @arturozunigaj Excelente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1512187226398076929</td>\n",
       "      <td>MITERRED</td>\n",
       "      <td>@mcubillossigall https://t.co/gkg5PwbZhZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1512187244248936452</td>\n",
       "      <td>piaelizabethvm</td>\n",
       "      <td>@simonlodijo @ruidosafest @franciscamusic @gio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266621</th>\n",
       "      <td>1525908559673712640</td>\n",
       "      <td>RichardDCorobo</td>\n",
       "      <td>@BottoConstituy1 El poder económico nunca va a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266622</th>\n",
       "      <td>1525981922115358720</td>\n",
       "      <td>AgainFlano</td>\n",
       "      <td>De @danielstingo no me lo esperaba ....\\nEstim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266623</th>\n",
       "      <td>1526319160849932288</td>\n",
       "      <td>opinion_liberal</td>\n",
       "      <td>El @danielstingo es un #ConvencionalCSM !!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266624</th>\n",
       "      <td>1525857323691950080</td>\n",
       "      <td>aguja9999</td>\n",
       "      <td>¿y @Contraloriacl ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266625</th>\n",
       "      <td>1525910904239321088</td>\n",
       "      <td>YouBet33</td>\n",
       "      <td>cc @patriciapolitz y su campaña de “desinforma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1266626 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id      screen_name  \\\n",
       "0        1512186668387913732      simonlodijo   \n",
       "1        1512186985850544129  MacaSimplemente   \n",
       "2        1512187189974683661  LuisVer75699645   \n",
       "3        1512187226398076929         MITERRED   \n",
       "4        1512187244248936452   piaelizabethvm   \n",
       "...                      ...              ...   \n",
       "1266621  1525908559673712640   RichardDCorobo   \n",
       "1266622  1525981922115358720       AgainFlano   \n",
       "1266623  1526319160849932288  opinion_liberal   \n",
       "1266624  1525857323691950080        aguja9999   \n",
       "1266625  1525910904239321088         YouBet33   \n",
       "\n",
       "                                                      text  \n",
       "0        @unveranonaranja @ruidosafest @franciscamusic ...  \n",
       "1        @LaSuRivas @ElisaLoncon @siliconvalle @Valdebe...  \n",
       "2          @teanval0207 @izkia @arturozunigaj Excelente...  \n",
       "3                 @mcubillossigall https://t.co/gkg5PwbZhZ  \n",
       "4        @simonlodijo @ruidosafest @franciscamusic @gio...  \n",
       "...                                                    ...  \n",
       "1266621  @BottoConstituy1 El poder económico nunca va a...  \n",
       "1266622  De @danielstingo no me lo esperaba ....\\nEstim...  \n",
       "1266623        El @danielstingo es un #ConvencionalCSM !!!  \n",
       "1266624                                ¿y @Contraloriacl ?  \n",
       "1266625  cc @patriciapolitz y su campaña de “desinforma...  \n",
       "\n",
       "[1266626 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen = df\n",
    "resumen = resumen[~resumen['text'].str.lower().str.contains(\"rt @\")] # quitar retweets\n",
    "resumen = resumen.reset_index().iloc[:, 1:]\n",
    "resumen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa gente que tiene más de 50 tweets, pues nos interesa acotar el costo computacional y es improbable que encontremos estilos similares entre dos autores que tienen menos tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma antes de filtro (1266626, 3)\n",
      "Forma después de filtro (553690, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma antes de filtro\", resumen.shape)\n",
    "tweet_count = resumen.groupby('screen_name').agg({'screen_name':'count'}).rename({'screen_name':'n'}, axis = 1)\n",
    "resumen = resumen[resumen.screen_name.isin(tweet_count[tweet_count.n > 50].index)]\n",
    "print(\"Forma después de filtro\", resumen.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar tweets demasiado cortos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_len = resumen.text.apply(len)\n",
    "resumen = resumen[tweet_len>80]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitar emojis, caracteres exóticos y stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen[\"clean_text\"] = resumen[\"text\"].apply(lambda x:  string_clean_pipeline(x))\n",
    "### Agrupar tweets por persona y aglutinar todos sus tweet en una fila. No recomendado\n",
    "# resumen = resumen.groupby('screen_name').agg({'clean_text':'sum', 'text':'sum', 'screen_name':'count'})\n",
    "# resumen[\"shingles\"] = resumen[\"clean_text\"].apply(lambda x: get_shingles(x))\n",
    "#resumen = resumen.rename({'screen_name':'tweet_count'}, axis = 1) \n",
    "#resumen = resumen[resumen.tweet_count > 40] # Conservar usuarios con mas de 40 tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shingling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos trabajar con shingles con k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shingles(text):\n",
    "    k = 5\n",
    "    result = set()\n",
    "    #text = text.split(\" \")\n",
    "    for i in range(len(text) - k-1):\n",
    "        shingle =  text[i:i+k] # By character\n",
    "        #shingle = \" \".join(text[i:i+k])# by trigram\n",
    "        result.add(shingle)\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>shingles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1512188055788027904</td>\n",
       "      <td>Rob92029357</td>\n",
       "      <td>@sokio @berfontaine No tienes como revatir alg...</td>\n",
       "      <td>@sokio @berfontaine revatir realidad expuesta ...</td>\n",
       "      <td>{perso, sta p, ad ex,  expu,  real, ta pe, ine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1512193611575799812</td>\n",
       "      <td>AlejoLatigo</td>\n",
       "      <td>@Hugo_Gutierrez_ Yaaaaaa yyyyyyyyy????????????...</td>\n",
       "      <td>@Hugo_Gutierrez_ Yaaaaaa yyyyyyyyy????????????...</td>\n",
       "      <td>{OCREC, ZOCRE, CRECE, ierre, rez_ , Serve, ECE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1512198930657955842</td>\n",
       "      <td>GordoUC_</td>\n",
       "      <td>@Molines01 @tere_marinovic Te están mostrando ...</td>\n",
       "      <td>@Molines01 @tere_marinovic estn mostrando rech...</td>\n",
       "      <td>{. pue, nes01,  terc,  most, mbre., derec, ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1512199583794835467</td>\n",
       "      <td>Orellana21Marce</td>\n",
       "      <td>@mdaza_abogado @Jess99041498 Es que la derecha...</td>\n",
       "      <td>@mdaza_abogado @Jess99041498 derecha quiere em...</td>\n",
       "      <td>{adrn , decen, 90414, 41498,  @Jes,  ladr,  go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1512212224613359617</td>\n",
       "      <td>PATRIOTCHILENO</td>\n",
       "      <td>@tere_marinovic @Sebasti45781359 Orsoni cero a...</td>\n",
       "      <td>@tere_marinovic @Sebasti45781359 Orsoni cero a...</td>\n",
       "      <td>{onta , 59 Or, 57813, 1359 , o apo, r mas, @Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id      screen_name  \\\n",
       "7   1512188055788027904      Rob92029357   \n",
       "20  1512193611575799812      AlejoLatigo   \n",
       "29  1512198930657955842         GordoUC_   \n",
       "30  1512199583794835467  Orellana21Marce   \n",
       "50  1512212224613359617   PATRIOTCHILENO   \n",
       "\n",
       "                                                 text  \\\n",
       "7   @sokio @berfontaine No tienes como revatir alg...   \n",
       "20  @Hugo_Gutierrez_ Yaaaaaa yyyyyyyyy????????????...   \n",
       "29  @Molines01 @tere_marinovic Te están mostrando ...   \n",
       "30  @mdaza_abogado @Jess99041498 Es que la derecha...   \n",
       "50  @tere_marinovic @Sebasti45781359 Orsoni cero a...   \n",
       "\n",
       "                                           clean_text  \\\n",
       "7   @sokio @berfontaine revatir realidad expuesta ...   \n",
       "20  @Hugo_Gutierrez_ Yaaaaaa yyyyyyyyy????????????...   \n",
       "29  @Molines01 @tere_marinovic estn mostrando rech...   \n",
       "30  @mdaza_abogado @Jess99041498 derecha quiere em...   \n",
       "50  @tere_marinovic @Sebasti45781359 Orsoni cero a...   \n",
       "\n",
       "                                             shingles  \n",
       "7   {perso, sta p, ad ex,  expu,  real, ta pe, ine...  \n",
       "20  {OCREC, ZOCRE, CRECE, ierre, rez_ , Serve, ECE...  \n",
       "29  {. pue, nes01,  terc,  most, mbre., derec, ran...  \n",
       "30  {adrn , decen, 90414, 41498,  @Jes,  ladr,  go...  \n",
       "50  {onta , 59 Or, 57813, 1359 , o apo, r mas, @Ma...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen[\"shingles\"] = resumen[\"clean_text\"].apply(lambda x: get_shingles(x))\n",
    "resumen.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar Vocabulario de Shingles a partir de su unión y mostrar su largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997134"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = resumen.loc[:, 'shingles']\n",
    "un = set().union(*d)\n",
    "len(un)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El vocabulario es demasiado largo para nuestros propósitos. Procedemos a contar cuantas en cuantos tweet aparece cada shingle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203726/203726 [00:03<00:00, 56593.93it/s]\n"
     ]
    }
   ],
   "source": [
    "shingle_count = dict()\n",
    "for row in tqdm(d):\n",
    "    for item_set in row:\n",
    "        try:\n",
    "            shingle_count[item_set] += 1\n",
    "        except KeyError:\n",
    "            shingle_count[item_set] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora conservamos los shingles que aparecen en al menos 230 tweets, para quedarnos con un vocabulario de alrededor de 10.000 shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9958\n"
     ]
    }
   ],
   "source": [
    "un_sample = [key for key, value in shingle_count.items() if value > 230] # smpling by freq\n",
    "print(len(un_sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, obtenemos un vocabulario más acotado que acorta los cómputos. Procedemos a guardar los shingles en un archivo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#un_sample = set(random.sample(un, 50000)) # random\n",
    "with open(\"shingles_sample.txt\", 'w') as file:\n",
    "    file.write(str(un_sample))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora convertimos la columna de shingles en tuplas para que sean más fáciles de guardar y releer desde un .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen.shingles = resumen.shingles.apply(lambda x: tuple(x))\n",
    "resumen.to_csv(\"preprocesado.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto terminamos con el preprocesamiento del archivo de tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareas_proce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
